---
---
@string{ieee = {IEEE}}

@inproceedings{xiang2023towards,
selected=true,
abbr={CDC 2023},
bibtex_show={true},
booktitle={2023 IEEE 62st Conference on Decision and Control (CDC)},
title={Towards Bias Correction of FedAvg over Nonuniform and Time-Varying Communications},
author={Xiang, Ming and Ioannidis, Stratis and Yeh, Edmund and Joe-Wong, Carlee and Su, Lili},
year={2023},
abstract={
<p>
Federated learning (FL) is a decentralized machine learning framework wherein a parameter server (PS) and a collection of clients collaboratively 
trains a model.  
Communication bandwidth is a scarce resource. In each round, the PS aggregates the updates from a subset of clients only. 
In this paper, we consider non-uniform and  time-varying communication between the PS and the clients. Specifically, in each round <i>t</i>, the link between the PS and client <i>i</i> is active with probability <it>p</it><sub>i</sub><sup>t</sup>, which is unknown to both the PS and the clients. 
This arises when 
the channel conditions are heterogeneous across clients and are changing over time.  

We show that when the <i>p</i><sub>i</sub><sup>t</sup>'s are not uniform (i.e., not identical over <i>i</i>), Federated Average (FedAvg) -- the most widely adopted FL algorithm -- fails to minimize the global objective. Observing this, we propose Federated Postponed Broadcast (FedPBC) which is a simple variant of FedAvg; it differs from FedAvg in that the PS postpones broadcasting the global model till the end of each round.  
FedPBC converges to a stationary point. 
Moreover, the staleness is mild and there is no significant slowdown. Both theoretical analysis and numerical results are provided. 
On the technical front,
postponing the global model broadcasts enables implicit gossiping among the clients with active links at round <i>t</i>. 
Consequently, we are able to control the perturbation of the global model dynamics caused by non-uniform and time-varying <i>p</i><sub>i</sub><sup>t</sup> via the techniques of controlling gossip-type information mixing errors.
</p>
},
arxiv={2306.00280},
publisher = ieee
}

@article{xiang2020state,
abbr={IEEE Access},
bibtex_show={true},
title={State-of-health prognosis for lithium-ion batteries considering the limitations in measurements via maximal information entropy and collective sparse variational gaussian process},
author={Xiang, Ming and He, Yigang and Zhang, Hui and Zhang, Chaolong and Wang, Lei and Wang, Chenyuan and Sui, Chunsong},
journal={IEEE Access},
volume={8},
pages={188199--188217},
year={2020},
publisher={IEEE},
html={https://ieeexplore.ieee.org/document/9216154}
}

@article{xiang2023federateddp,
abbr={Submitted},
title={Federated SGD with Differentially Private and Byzantine Resilient One-Bit Compressors},
author={Xiang, Ming and Su, Lili},
year={2023},
publisher={IEEE},
arxiv={2210.00665}
}